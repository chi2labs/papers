---
title: |
  \begin{center}\rule{1\linewidth}{2pt}\end{center}
  \text{Chi Square Mobile for Emergency Onlined Courses}
  \text{Field Test Results}
  \begin{center}\rule{1\linewidth}{2pt}\end{center}
subtitle: |
  A Preprint
date: "April 3 2021"
keywords:
  - Emergency onlined courses
  - Learning Analytics
  - Learning Loss
  - Covid Pandemic
bibliography: references.bib
biblio-style: unsrt
output: 
  bookdown::pdf_document2:
    toc: false
    keep_tex: true
    extra_dependencies: ["float"]
---

```{r setup, include=FALSE}
library(tidyverse)
library(kableExtra)
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning = FALSE)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")

## Data 
participants <- read_rds(here::here("data","users.rds"))
quiz_answers <- read_rds(here::here("data","quiz_answers.rds"))

# filter out some participants
participants <- participants %>% 
  filter(!last_name%in% c("Magadán", "Dietrichson","Pagnone"))

quiz_answers <- quiz_answers %>% #Remove our spurious answers as well
  filter(respondent_id %in% participants$user_id)

theme_set(theme_minimal())
update_geom_defaults("bar", list(fill="red"))
update_geom_defaults("line", list(color="red"))

```


```{=tex}
\begin{table}[ht]
\centering % used for centering table
\begin{tabular}{c c c c} % centered columns (2 columns)

\textbf{Aleksander Dietrichson} &  & & \textbf{Cecilia Magadán} \\ 
Chi Square Laboriatories & & & Centro de Estudios Lingüísticos en Sociedad\\
New York, NY 10023 &  &     &Universidad San Martín\\
dietrichson@gmail.com   &  & &Buenos Aires, Argentina\\
                      &   & & ceciliamagadan@gmail.com \\

\end{tabular}
\label{table:nonlin} % is used to refer this table in the text
\end{table}
```




```{=tex}
\begin{abstract}

At the onset of the COVID pandemic, thousands of courses were emergency onlined.

As a response to these new and unfamiliar conditions a mobile app was developed and deployed to

mitigate some of the learning loss produced. This paper presents experiences and related findings

from this deployment.

\end{abstract}
```

---

# Introduction 
In the Republic of Argentina the COVID-19 pandemic was declared toward the end of February of 2020. Our geographic location in the southern hemisphere meant that it his toward the end of summer, with most schools coming off a two-month summer break. The emergency measures put in place by public health authorities meant that thousands of courses which would normallly be taught in a face-to-face setting would now have to be onlined. While most institutions have access to learning management systems, these sytems were unfamiliar to most instructors and widely deemed unsuited for the purpose, and most instructors opted for a synchronous format using some kind of videoconferencing system such as Meet, Teams or Big Blue Button. Legal and administrative requirements stating that a course session needed to have a start and end time also tilted the weight in favor of these options. 

# The Concept of Learning Loss 

## Non verbal communication

# The Chi Square Mobile App 

In the given 

Build with several R packages, the most important ones of which were: {shinyMobile}[@shinyMobile:2020] and {chi2Mobile}[@chi2Mobile:2020].


In Figure \ref{fig:studentapp} we see the main interfaces.

\begin{figure}[H]
\centering
\includegraphics[width=5cm]{images/outputfile_4.png}
\includegraphics[width=5cm]{images/outputfile_5.png}
\includegraphics[width=5cm]{images/outputfile_6.png}
\caption{Main App Interfaces for the Student}
\label{fig:studentapp}
\end{figure}


Figure \@ref(fig:instructorapp) Shows some of the interfaces available for the instructor.



\begin{figure}[H]
\centering
\includegraphics[width=5cm]{images/outputfile_5006.png}
\includegraphics[width=5cm]{images/outputfile_1002.png}
\includegraphics[width=5cm]{images/outputfile_2003.png}
\caption{Main App Interfaces for the Instructor}
\label{fig:instructorapp}
\end{figure}


# Context and Participants

A cohort of `r nrow(participants)` students, enrolled in *Gramatica*, an introductory level linguistic course taught by one of the authors, were asked to download and install the application on their devices. A total of `r quiz_answers$respondent_id %>% unique %>% length` complied with these instructions and responded at least once. The course had a duration of sixteen weeks, with additional final exam options at the end of the semester. Figure \ref{fig:respondents-per-week} shows the number of students who responded to the request for feedback during the semester. We see a sharp drop-off in week six, and a relatively stable number thereafter.




```{r respondents-per-week, fig.height=2, fig.cap="Respondents per Week of the Course"}
quiz_answers$date <- as.Date(quiz_answers$time_stamp)
quiz_answers$week <- lubridate::week(quiz_answers$time_stamp)
quiz_answers$week_of_course <- quiz_answers$week - min(quiz_answers$week) +1
quiz_answers %>% 
  group_by(week_of_course) %>% 
  summarize(N=n_distinct(respondent_id)) %>% 
  ggplot(aes(x=week_of_course,y=N))+
  geom_line(color="red")+
  geom_point(color="red")+
  geom_smooth(lty=2, se=FALSE,color="gray")+
  ylab("Respondents")+
  xlab("Week of the Course")+
  scale_x_continuous(breaks = c(1,5,9,13))
```

# Reponses to Star-Ratings

The student were asked to provide star-ratings (1-5) to four questions. These were:

* *Claridad de la(s) lectura(s)* [Clarity of the readings]
* *Claridad de la presentación* [Clarity of the presentation]
* *Conocimentos previos* [Prior knowledge]
* *Calidad de la conectividad* [Connectivity]

The star-ratings in these categories are shown in Figure \@ref(fig:star-ratings-per-week).

```{r star-ratings-per-week, fig.cap="Average Star-Rating per Week"}
quiz_answers %>% 
  filter(question %in% c("Calidad de la conectividad", "Claridad de la(s) lectura(s)", "Claridad de la presentación", "Conocimentos previos" )) %>% 
  group_by(week_of_course, question) %>% 
  summarize(
    "Mean Rating" = mean(as.numeric(answer),na.rm=TRUE),
    "Median Rating" = median(as.numeric(answer),na.rm=TRUE)
            ) %>% 
  ggplot(aes(x=week_of_course, y=`Mean Rating`, color = question))+
  geom_line(key_glyph = "timeseries")+
  geom_point(key_glyph  = "timeseries")+
  guides(color=guide_legend(nrow=2))+
  theme(legend.position = "top", legend.title = element_blank())+
  xlab("Week of the Course")+
  scale_x_continuous(breaks = c(1,5,9,13))+
  scale_y_continuous(limits = c(1,5))
```

## Real use of scale

While the students have five options to choose from when giving a star rating, it is not necessarily clear whether they in fact use the whole scale. Figure \@ref(fig:star-ratings-overall) shows the distribution of stars for each of the four star-rated questions used in the questionnaire.

```{r star-ratings-overall, fig.cap="Comparison of Star Ratings"}
quiz_answers %>% 
  filter(question %in% c("Calidad de la conectividad", "Claridad de la(s) lectura(s)", "Claridad de la presentación", "Conocimentos previos" )) %>% 
  mutate(Stars = as.numeric(answer)) %>% 
  group_by(question) %>% 
  # summarize(
  #   "Minimum" = min(as.numeric(answer),na.rm=TRUE),
  #   "Maximum" = max(as.numeric(answer),na.rm=TRUE)
  # ) %>% 
  ggplot(aes(x=Stars))+
  geom_histogram()+
  theme(plot.caption = element_text(hjust = 0))+
  scale_y_continuous(labels = NULL) +
  ylab(NULL)+
  facet_wrap(~question,ncol = 1)+
  theme(
  strip.text.x = element_text(hjust=0)
  )
```

We see that the full scale of the star-ratings is only present in the answers to the question of prior knowledge. 


# Linguistic Analysis

The feedback from students also included two open-ended questions. These were:

* *Conceptos que aprendiste* [Concepts learned]
* *Conceptos que necesitás revisar* [Concepts for review]

The interface provided to the students allows for input of any length, i.e. the indivual concepts could be multiple words, (see Figure \@ref(fig:studentapp)), separated by the <enter> key. Once enter was hit, the word or words were visually indicated to be of the same group. The interaction described is *standard* for this type of input on a mobile device.

The purpose of this question and the selected interface was to elicit key-terms for each category as this would facilitate automatization of the linguistic analysis. In practice, however, some proportion of the did not enter the data as expected. It is not clear whether this was because the field format was deemed inappropriate for the purpose, the instructions were unclear or due to lack of familiarity with this type of interface. A software update was made to the instructor app (Figure \@ref(fig:instructorapp)) to enhance the interpretability of the feedback, however, the researchers chose not to make any changes to the student interface.

Several different *feedback formats* were observed. While most students used the interface as intended (*Norm*), some chose not to answer the open-ended questions, some chose to submit a list, separated by commas and/or other connectors, and some chose a longer-form style of feedback. Table \@ref(tab:input-strategy-used) summarizes these.

```{r deduplication}
# Deduplication 
# Turns out there was a bug in the code that led to duplicated answers for the linguistic input. This was fixed after week 2
quiz_answers %>% 
  filter(question_type == "KW") %>% 
  select(question, answer, week_of_course, request_id, 
         respondent_id, question_id) %>% 
 group_by(respondent_id, request_id, question_id, question, answer,week_of_course) %>% 
  tally() %>% 
  arrange(desc(desc(week_of_course),desc(n)))  -> quiz_answers2

```

```{r}
quiz_answers2 <- quiz_answers2 %>%
  select(answer,everything())

quiz_answers2 <- quiz_answers2 %>% 
  mutate(answer2 = ifelse(answer =="NULL", NA,answer) ) %>%  # No answer
  mutate(response_type = 
           case_when(
             is.na(answer2) ~ "N/A",
             startsWith(answer2,"c(") ~ "Norm",
             stringr::str_detect(answer2, ",") > 0 ~ "Comma",
             stringr::str_detect(answer2, " e ") > 0 ~ "Comma", #connector
             stringr::str_detect(answer2, " y ") > 0 ~ "Comma", #connector
             stringr::str_detect(answer2, " vs. ") > 0 ~ "Comma", #connector
             stringr::str_detect(answer2, " - ") > 0 ~ "Comma", #connector
             stringr::str_detect(answer2," ", negate = TRUE) ~ "Norm"
             #, #Single word
             ,stringr::str_count(answer2," ") == 1 ~ "Norm" #two words
             ,stringr::str_count(answer2," ") == 2 ~ "Norm" #three words
             ,TRUE ~ "Long form"
           )
  ) 

# I tried doing this with the tidyverse case_when + lengt(eval(...etc. But it seems evaluation always happens first so
tmp <- quiz_answers2 %>% 
  select(respondent_id, request_id, question_id,answer2) %>% 
  filter(startsWith(answer2,"c(")) %>% 
  mutate(concept_count = length(eval(parse(text=answer2)))) %>% 
  mutate(concepts =
           stringr::str_flatten(eval(parse(text=answer2)),collapse="|" )
  )

quiz_answers2 <- quiz_answers2 %>% 
  left_join(tmp)

# Now parse the rest
tmp2 <- quiz_answers2 %>% 
  mutate(
    concept_count = 
      case_when(
        !is.na(concept_count) ~ concept_count, #i.e. do nothing
        response_type == "Comma" ~ length(stringr::str_split(answer2,"\\sy\\s|\\so\\s|,|vs\\.|\\/")),
        response_type == "Norm" & is.na(concept_count) ~ 
          length(stringr::str_split(answer2," "))
        #  ,TRUE ~ length(stringr::str_split(answer2," "))
      )
  ) %>% 
  mutate(
    concepts = 
      case_when(
        !is.na(concept_count) ~ concepts, #i.e. do nothing
        response_type == "Comma" ~ stringr::str_replace_all(answer2,"\\sy\\s|\\so\\s|,|vs\\.", " "),
        response_type == "Norm" & is.na(concept_count) ~ answer2
        #  ,TRUE ~ length(stringr::str_split(answer2," "))
      )
  )  

quiz_answers2 <- tmp2
rm(tmp);rm(tmp2);
```

```{r input-strategy-used, }
  quiz_answers2 %>% 
    group_by(response_type, question) %>% 
    count %>% 
    rename(Question=question) %>% 
    pivot_wider(names_from = "response_type", values_from = "n") %>% 
  select(Question,`N/A`, Norm, Comma, `Long form`) %>%
    knitr::kable(caption = "Input Strategies Observed",
                 booktabs = TRUE) %>%
    add_header_above(c(" ", " ", "Format" = 3), bold = TRUE, italic = TRUE)
```
Except for the non-reply, which is a legitimate answer to any of the questions posed, the format of the feedback is significant to the type of processing that is needed to extract, summarize and analyze the linguistic data.
```{r}
quiz_answers2 %>% 
  filter(!is.na(concept_count)) %>% 
  group_by(week_of_course,question) %>% 
  summarize(
    concepts = sum(concept_count,na.rm = TRUE),
    respondents = n_distinct(respondent_id)
  ) %>% 
  mutate(concepts_per_student = concepts/respondents) -> tmp

mean_learned <- tmp %>% filter(question == "Conceptos que aprendiste") %>% pull(concepts_per_student) %>% mean %>% 
  round(digits=1)
concepts_requested <- tmp %>% filter(question != "Conceptos que aprendiste") %>% pull(concepts_per_student) 

```


## Number of Concepts Learned and Requested

We parsed the data using the appropriate technique depending on the input strategy used by the students. We then counted the number of concepts in all non-empty inputs across the fourteen weeks of the course. Figure \@ref(fig:concepts-per-student) summarizes these results. We see that requests for review of concepts remained relatively stable throughout the course, with a mean of `r mean(concepts_requested) %>% round(digits=1)` and a standard deviation of `r sd(concepts_requested) %>% round(digits=1)`, while the number of concepts learned show a significant increase in weeks 9-11. It is also worth noting that at no point during the course do the students on average report learning fewer concepts than those needing review.


```{r concepts-per-student, fig.cap="Concepts Input per Student Per Week of the Course"}
tmp %>% 
  ggplot(aes(x = week_of_course, y = concepts_per_student, color=question ))+
  geom_line(key_glyph = "timeseries")+
  geom_point(key_glyph  = "timeseries")+
  theme(legend.position = "top", legend.title = element_blank())+
  xlab("Week of the Course")+
  ylab("Number of Concepts")+
  scale_x_continuous(breaks = c(1,5,9,13))+
  scale_y_continuous(limits = c(0,15))
```

## N-gram Analysis

N-gram analysis was performed [@tidytext:2016]

```{r}
library(tidytext)
## Stop_words for unigrams
stop_words_unigrams <- data.frame(
  ngram = c(
    "que",
    "y",
    "de",
    "la",
    "los",
    "las",
    "al",
    "del",
    "un",
    "una",
    "a",
    "vs",
    "me",
    "sobre",
    "es",
    "no",
    "o",
    "e",
    "en",
    "se",
    "entre",
    "como",
    "con",
    "el", 
    "ella")
)

# TODO: Something with accents - they are not consistently added.

unigrams <-
  quiz_answers2 %>%
  ungroup %>% 
  select(concepts, question, week_of_course) %>% 
  unnest_tokens(ngram, concepts, token = "words" ) %>% 
  anti_join(stop_words_unigrams) 

```


```{r}
bigrams <-
  quiz_answers2 %>%
  ungroup %>% 
  unnest_tokens(ngram, concepts, token = "ngrams", ngram_delim=" ", n = 2L) %>% 
  select(ngram,question, week_of_course)
```

```{r}
trigrams <-
  quiz_answers2 %>%
  ungroup %>% 
  unnest_tokens(ngram, concepts, token = "ngrams", ngram_delim=" ", n = 3L) %>% 
  select(ngram,question, week_of_course)

```


```{r unigram-table}
unigrams %>%
  group_by(week_of_course,ngram) %>%
  tally %>%
  filter(!is.na(ngram)) %>%
  group_by(week_of_course) %>%
  arrange(desc(n),.by_group = TRUE) %>%
  filter(row_number()<=10) %>% 
  arrange(ngram, .by_group = TRUE) -> tmp


  # 7 column matrix
  tmp2 <- matrix(nrow = 22, ncol = 7)
  # Insert "headings"
  tmp2[1,] <- paste0("Week ",1:7)
  tmp2[2:11,] <- tmp$ngram[1:70]
  tmp2[12,] <- paste0("Week ",8:14)
  tmp2[13:22,] <- tmp$ngram[71:140]
  
  
  tmp2 %>%
    knitr::kable(booktabs=TRUE, align = 'l', 
                 caption = "Top Unigrams per Week",
                 linesep = c(rep("",10),"\\addlinespace")) %>% 
    row_spec(c(1,12), bold=TRUE)
```









# References
